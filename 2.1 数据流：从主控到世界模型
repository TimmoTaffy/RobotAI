# 数据流设计：从主控到世界模型

下面用端到端流程图说明数据处理及核心标准化工作：

1. 主控发送数据 (JSON)
• 输出：结构化 JSON（见 2.3 主控输出JSON协议）
• 包含：timestamp, imu, wheel, lidar, radar_station, vision, turret 等传感器字段

2. 串口接收 (SerialReceiver)
• 功能：接收并解析主控 JSON，添加本地时间戳，转换数组为 numpy.ndarray
• 输出：预处理后的原始数据字典

3. 数据标准化
• 将原始字典转换为标准数据类型（定义在 common/types.py）：
  - ImuData: imu 数据
  - WheelData: 轮速计数据
  - LidarData: 点云数据
  - TurretState: 云台姿态和电机角度
  - RadarStationData: 雷达站识别结果
  - VisionData: 视觉识别结果
• 示例：
```python
from common.types import ImuData
imu_data = ImuData(
    timestamp=raw["timestamp"],
    frame_id="imu_link",
    angular_velocity=raw["imu"]["gyro"],
    linear_acceleration=raw["imu"]["acc"],
    orientation=np.array([0.0, 0.0, raw["imu"]["yaw"]])
)
```

4. 坐标变换
• 使用 Transform, Pose2D, Pose3D 类型统一描述变换关系
• 调用 transforms 模块接口：
  - camera_to_vehicle, lidar_to_vehicle, turret_to_vehicle, vehicle_to_world

5. 模块处理
• 位姿估计：DeadReckoning, EKFFusion, TurretPose → 输出 Pose2D, TurretState
• 环境感知：LidarProcessor, RadarStation, Vision → 输出障碍列表、目标列表
• 目标跟踪：TargetTracker → 融合多源数据，维护目标状态

6. WorldModel 更新
• 使用标准类型填充 world_model.py 中的属性：
```python
wm.self_pose = vehicle_pose                  # Pose2D
wm.turret_state = turret_state               # TurretState
# 使用 map_builder 生成栅格地图并更新世界模型
occupancy_grid, dynamic_clusters = build_map(lidar_data.points, grid_size, map_size, wm)
# 或者直接赋值
wm.occupancy_grid = occupancy_grid           # np.ndarray 二维栅格地图
wm.dynamic_obstacles = dynamic_clusters      # List[np.ndarray] 动态障碍簇列表
wm.robots = tracked_targets                  # List[RobotInfo]
```
• 最终得到包含定位、地图、障碍、目标的完整世界模型，供决策、规划和可视化使用